---
title: "American Lobster (Homarus americanus) - Complete Workflow"
author: "Paung Khuat"
date: "`r Sys.Date()`"
output: github_document
---

# Overview

This document contains the complete species distribution modeling workflow for **American Lobster (*Homarus americanus*)**, covering all chapters from C00 (Coding) through C05 (Prediction).

---

# C00: Coding Basics

## Setup and Loading Tools

For any coding project we need to load the necessary packages. We have a single file that will install (if needed) and load each package.

```{r setup, warning = FALSE, message = FALSE}
source("setup.R")
SPECIES = "Homarus americanus"

# Custom theme for maps to prevent x-axis label collision
theme_map <- function() {
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
    axis.text.y = element_text(size = 7)
  )
}
```

## Spatial Data Overview

### Point Data - Buoys in Gulf of Maine

```{r buoys}
buoys = gom_buoys()
buoys
```

### Coastline Data

```{r coast}
coast = read_coastline()
plot(coast, col = "orange", lwd = 2, axes = TRUE, reset = FALSE,
     main = "Gulf of Maine Region")
plot(st_geometry(buoys), pch = 16, cex = 0.5, add = TRUE)
text(st_geometry(buoys), labels = buoys$id, cex = 0.7, adj = c(1,-0.1))
```

### Brickman Environmental Data

Load the Brickman database and filter for present monthly climatology:

```{r brickman_database}
db = brickman_database() |>
  filter(scenario == "PRESENT", interval == "mon")
present = read_brickman(db)
present
```

Plot sea surface temperature by month:

```{r plot_sst}
plot(present['SST'])
```

---

# C01: Observations

## Download and Read OBIS Data

Read the observations for American Lobster:

```{r read_obs}
obs = read_obis(SPECIES)
obs
```

Track the starting dimensions:

```{r dim_start}
dim_start = dim(obs)
dim_start
```

## Explore basisOfRecord

```{r basisOfRecord}
obs |> count(basisOfRecord)
```

## Check for Missing Data

```{r summary_obs}
summary(obs)
```

## Filter by eventDate

Remove records with missing eventDate:

```{r filter_date}
obs = obs |>
  filter(!is.na(eventDate))
```

## Filter by individualCount

Remove records with missing individualCount:

```{r filter_count}
obs = obs |>
  filter(!is.na(individualCount))
summary(obs)
```

## Filter by Year

Keep observations from 1970 onwards (aligns with Brickman climatology):

```{r plot_year}
ggplot(data = obs,
       mapping = aes(x = year)) + 
  geom_bar() + 
  geom_vline(xintercept = c(1982, 2013), linetype = "dashed") + 
  labs(title = paste(SPECIES, "- Counts per year"))
```

```{r filter_year}
obs = obs |>
  filter(year >= 1970)
dim(obs)
```

## Distribution by Month

```{r month_ordered}
obs = obs |>
  mutate(month = factor(month, levels = month.abb))

ggplot(data = obs,
       mapping = aes(x = month)) + 
  geom_bar() + 
  labs(title = paste(SPECIES, "- Counts per month"))
```

## Filter by Brickman Mask

Check which observations fall within the Brickman data domain:

```{r mask}
db = brickman_database() |>
  filter(scenario == "STATIC", var == "mask")
mask = read_brickman(db)
```

```{r plot_mask}
plot(mask, breaks = "equal", axes = TRUE, reset = FALSE)
plot(st_geometry(obs), pch = ".", add = TRUE)
```

```{r mask_extract}
hitOrMiss = extract_brickman(mask, obs)
count(hitOrMiss, value)
```

Filter to keep only observations within the mask:

```{r filter_mask}
obs = obs |>
  filter(!is.na(hitOrMiss$value))
dim(obs)
```

## Save Filtered Observations

The filtered observations are now ready for background sampling.

Final count comparison:

```{r dim_final}
dim_final = dim(obs)
cat("Starting observations:", dim_start[1], "\n")
cat("Final observations:", dim_final[1], "\n")
cat("Records removed:", dim_start[1] - dim_final[1], "\n")
```

---

# C02: Background Sampling

## Load Data

```{r load_obs_mask}
coast = read_coastline()
# obs is already filtered from C01 above
db = brickman_database() |>
  filter(scenario == "STATIC", var == "mask")
mask = read_brickman(db)
```

## Plot Observations by Month

```{r all_observations}
LON0 = -67
LAT0 = 46
all_counts = count(st_drop_geometry(obs), month)

ggplot() +
  geom_sf(data = obs, alpha = 0.2, shape = "circle small", size = 1) +
  geom_sf(data = coast, col = "orange") +
  geom_text(data = all_counts,
            mapping = aes(x = LON0, 
                          y = LAT0, 
                          label = sprintf("n: %i", .data$n)),
                          size = 3) + 
  labs(x = "Longitude", y = "Latitude", 
       title = paste(SPECIES, "- All observations")) +
  facet_wrap(~month) +
  theme_map()
```

## Thinning Observations

Thin observations so we have at most one observation per Brickman cell:

```{r thin_observations}
thinned_obs = sapply(month.abb,
               function(mon){ 
                 thin_by_cell(obs |> filter(month == mon), mask)
               }, simplify = FALSE) |>
  dplyr::bind_rows() 

thinned_counts = count(st_drop_geometry(thinned_obs), month)

ggplot() +
  geom_sf(data = thinned_obs, 
          alpha = 0.2, 
          shape = "circle small", 
          size = 1) +
  geom_sf(data = coast, col = "orange") +
  geom_text(data = thinned_counts,
            mapping = aes(x = LON0, 
                          y = LAT0, 
                          label = sprintf("n: %i", .data$n)),
                          size = 3) + 
  labs(x = "Longitude", y = "Latitude", 
       title = paste(SPECIES, "- Thinned observations")) +
  facet_wrap(~month) +
  theme_map()

cat("Original observations:", nrow(obs), "\n")
cat("After thinning:", nrow(thinned_obs), "\n")
```

## Create Bias Map

Build a sampling bias map using original observation density:

```{r bias_map}
bias_map = rasterize_point_density(obs, mask)

ggplot() +
  geom_stars(data = bias_map, aes(fill = count)) +
  scale_fill_viridis_b(na.value = "transparent") +
  geom_sf(data = coast, col = "orange") + 
  labs(x = "Longitude", y = "Latitude", 
       title = paste(SPECIES, "- Bias map")) +
  theme_map()
```

## Sample Background Points

Calculate average number of observations per month for background sampling:

```{r n_background}
nback_avg = mean(all_counts$n) |> round()
cat("Background points per month:", nback_avg, "\n")
```

Sample background points using biased sampling:

```{r sample_background}
obsbkg = sapply(month.abb,
    function(mon){ 
      sample_background(thinned_obs |> filter(month == mon),
                       bias_map,
                       method = "bias",
                       return_pres = TRUE,
                       n = nback_avg) |>
        mutate(month = mon, .before = 1)
    }, simplify = FALSE) |>
  bind_rows() |>
  mutate(month = factor(month, levels = month.abb))

count(st_drop_geometry(obsbkg), month, class)
```

## Plot Presence vs Background

```{r plot_presence_background}
ggplot() +
  geom_sf(data = obsbkg, 
          mapping = aes(col = class),
          alpha = 0.4, shape = "circle small", size = 1) +
  geom_sf(data = coast, col = "orange")  + 
  labs(x = "Longitude", y = "Latitude", 
       title = paste(SPECIES, "- Presence and Background")) +   
  scale_fill_okabe_ito() +
  facet_wrap(~month) +
  theme_map()
```

## Save Model Input

```{r save_model_input}
write_model_input(obsbkg, scientificname = SPECIES, version = "v1")
cat("Model input saved for", SPECIES, "\n")
```

---

# C03: Covariates

## Read Covariates

```{r read_covariates}
db = brickman_database() |>
  dplyr::filter(scenario == "PRESENT", interval == "mon")
present = read_brickman(db)
```

## Pairs Plot - Collinearity Check

```{r pairs_plot}
pairs(present)
```

## Filter Collinear Variables

```{r filter_collinear}
keep = filter_collinear(present, method = "cor_caret", cutoff = 0.65)
keep

drop_me = attr(keep, "to_remove")
cat("Variables to drop:", paste(drop_me, collapse = ", "), "\n")
```

Add depth and month (always important for marine ecology):

```{r add_depth_month}
keep = c("depth", "month", keep)
cat("Variables to keep:", paste(keep, collapse = ", "), "\n")
```

## Load Model Input and Extract Covariates

```{r reload_model_input}
model_input = read_model_input(scientificname = SPECIES, version = "v1")
present = read_brickman(add = c("depth"))
variables = extract_brickman(present, model_input, form = "wide")
```

Add class variable:

```{r add_class}
variables = variables |>
  mutate(class = model_input$class) |>
  select(-.id)
```

## Compare Presence vs Background

```{r plot_pres_vs_bg, warning = FALSE, fig.height = 8}
plot_pres_vs_bg(variables |> select(-month), "class")
```

## Save Configuration

```{r save_config}
cfg = list(
  version = "v1",
  scientificname = SPECIES,
  background = "average of observations per month",
  keep = keep
)

ok = make_path(data_path("models"))
write_configuration(cfg)
cat("Configuration saved for", SPECIES, "version v1\n")
```

## Save Updated Model Input with Covariates

```{r save_model_input_v1}
write_model_input(variables, scientificname = SPECIES, version = "v1")
```

---

# C04: Models

## Load Data and Configuration

```{r load_model_data}
cfg = read_configuration(scientificname = SPECIES, version = "v1")
model_input = read_model_input(scientificname = SPECIES, 
                               version = "v1",
                               log_me = c("depth", "Xbtm")) |>
  dplyr::mutate(month = month_as_number(.data$month)) |>
  select(all_of(c("class", cfg$keep)))
```

## Split Data: Training and Testing

```{r initial_split}
model_input_split = spatial_initial_split(model_input, 
                        prop = 1 / 5,
                        strategy = spatial_block_cv)
model_input_split
```

```{r plot_split}
autoplot(model_input_split)
```

## Cross-Validation Folds

```{r cv_folds}
tr_data = training(model_input_split)
cv_tr_data <- spatial_block_cv(tr_data,
  v = 5,     
  cellsize = grid_cellsize(model_input),
  offset = grid_offset(model_input) + 0.00001
)
autoplot(cv_tr_data)
```

## Build Recipe

```{r recipe}
one_row_of_training_data = dplyr::slice(tr_data, 1)
rec = recipe(one_row_of_training_data, formula = class ~ .)
summary(rec)
```

## Create Workflow with Multiple Models

```{r workflow}
wflow = workflow_set(
  
  preproc = list(default = rec),
  
  models = list(
    
      glm = logistic_reg(
          mode = "classification") |>
        set_engine("glm"),
      
      rf = rand_forest(
          mtry = tune(),
          trees = tune(),
          mode = "classification") |>
        set_engine("ranger", 
                   importance = "impurity"),
      
      btree = boost_tree(
          mtry = tune(), 
          trees = tune(), 
          tree_depth = tune(), 
          learn_rate = tune(), 
          loss_reduction = tune(), 
          stop_iter = tune(),
          mode = "classification") |>
        set_engine("xgboost"),
    
      maxent = maxent(
          feature_classes = tune(),
          regularization_multiplier = tune(),
          mode = "classification") |>
        set_engine("maxnet")
  )
)
wflow
```

## Define Metrics

```{r metrics}
metrics = sdm_metric_set(yardstick::accuracy)
metrics
```

## Tune Hyperparameters

```{r fit_models, warning = FALSE, message = FALSE}
wflow <- wflow |>
  workflow_map("tune_grid",
    resamples = cv_tr_data, 
    grid = 3,
    metrics = metrics, 
    verbose = TRUE)
```

```{r plot_tuning}
autoplot(wflow)
```

## Select Best Models

```{r select_best}
model_fits = workflowset_selectomatic(wflow, model_input_split,
                                  filename = "Homarus_americanus-v1-model_fits",
                                  path = data_path("models"))
model_fits
```

## Model Performance

```{r model_metrics}
model_fit_metrics(model_fits)
```

```{r confusion_matrix}
model_fit_confmat(model_fits)
```

---

# C05: Prediction

## Load Configuration and Brickman Data

```{r load_prediction_data}
cfg = read_configuration(scientificname = SPECIES,
                         version = "v1", 
                         path = data_path("models"))

db = brickman_database()

present_conditions = read_brickman(db |> filter(scenario == "PRESENT", 
                                                interval == "mon"),
                       add = c("depth", "month")) |>
  select(all_of(cfg$keep))
```

## Load Model Fits

```{r load_model_fits}
model_fits = read_model_fit(filename = "Homarus_americanus-v1-model_fits")
model_fits
```

## Nowcast (Present Conditions)

```{r nowcast}
nowcast = predict_stars(model_fits, present_conditions)
nowcast
```

```{r plot_nowcast, warning = FALSE}
plot_prediction(nowcast['default_btree'])
```

### Presence/Absence Map

```{r plot_pa_nowcast, warning = FALSE}
pa_nowcast = threshold_prediction(nowcast)
plot_prediction(pa_nowcast['default_btree'])
```

## Forecasts

### RCP45 - 2055

```{r forecast_rcp45_2055, warning = FALSE}
covars_rcp45_2055 = read_brickman(db |> filter(scenario == "RCP45", 
                                               year == 2055, 
                                               interval == "mon"),
                                  add = c("depth", "month")) |>
  select(all_of(cfg$keep))

forecast_rcp45_2055 = predict_stars(model_fits, covars_rcp45_2055)
plot_prediction(forecast_rcp45_2055['default_btree'])
```

### RCP45 - 2075

```{r forecast_rcp45_2075, warning = FALSE}
covars_rcp45_2075 = read_brickman(db |> filter(scenario == "RCP45", 
                                               year == 2075, 
                                               interval == "mon"),
                                  add = c("depth", "month")) |>
  select(all_of(cfg$keep))

forecast_rcp45_2075 = predict_stars(model_fits, covars_rcp45_2075)
plot_prediction(forecast_rcp45_2075['default_btree'])
```

### RCP85 - 2055

```{r forecast_rcp85_2055, warning = FALSE}
covars_rcp85_2055 = read_brickman(db |> filter(scenario == "RCP85", 
                                               year == 2055, 
                                               interval == "mon"),
                                  add = c("depth", "month")) |>
  select(all_of(cfg$keep))

forecast_rcp85_2055 = predict_stars(model_fits, covars_rcp85_2055)
plot_prediction(forecast_rcp85_2055['default_btree'])
```

### RCP85 - 2075

```{r forecast_rcp85_2075, warning = FALSE}
covars_rcp85_2075 = read_brickman(db |> filter(scenario == "RCP85", 
                                               year == 2075, 
                                               interval == "mon"),
                                  add = c("depth", "month")) |>
  select(all_of(cfg$keep))

forecast_rcp85_2075 = predict_stars(model_fits, covars_rcp85_2075)
plot_prediction(forecast_rcp85_2075['default_btree'])
```

## Compare Predictions

```{r compare_predictions, warning = FALSE, fig.width = 12, fig.height = 10}
library(patchwork)

p1 = plot_prediction(nowcast['default_btree']) + 
  ggtitle("PRESENT")
p2 = plot_prediction(forecast_rcp45_2055['default_btree']) + 
  ggtitle("RCP45 - 2055")
p3 = plot_prediction(forecast_rcp45_2075['default_btree']) + 
  ggtitle("RCP45 - 2075")
p4 = plot_prediction(forecast_rcp85_2055['default_btree']) + 
  ggtitle("RCP85 - 2055")
p5 = plot_prediction(forecast_rcp85_2075['default_btree']) + 
  ggtitle("RCP85 - 2075")

(p1 | p2 | p3) / (p4 | p5) +
  plot_annotation(title = paste(SPECIES, "- Habitat Suitability Predictions"),
                  subtitle = "Boosted Tree Model")
```

## Save Predictions

```{r save_predictions}
path = make_path("predictions")

write_prediction(nowcast,
                 scientificname = cfg$scientificname,
                 version = cfg$version,
                 year = "CURRENT",
                 scenario = "CURRENT")

write_prediction(forecast_rcp45_2055,
                 scientificname = cfg$scientificname,
                 version = cfg$version,
                 year = "2055",
                 scenario = "RCP45")

write_prediction(forecast_rcp45_2075,
                 scientificname = cfg$scientificname,
                 version = cfg$version,
                 year = "2075",
                 scenario = "RCP45")

write_prediction(forecast_rcp85_2055,
                 scientificname = cfg$scientificname,
                 version = cfg$version,
                 year = "2055",
                 scenario = "RCP85")

write_prediction(forecast_rcp85_2075,
                 scientificname = cfg$scientificname,
                 version = cfg$version,
                 year = "2075",
                 scenario = "RCP85")

cat("All predictions saved!\n")
```

---

# Summary

This document walked through the complete species distribution modeling workflow for **American Lobster (*Homarus americanus*)**:

| Chapter | Topic | Key Steps |
|---------|-------|-----------|
| C00 | Coding Basics | Setup, spatial data types |
| C01 | Observations | Download OBIS data, filter and clean |
| C02 | Background | Thin observations, create bias map, sample background |
| C03 | Covariates | Check collinearity, select variables, save configuration |
| C04 | Models | Train GLM, Random Forest, Boosted Tree, MaxEnt |
| C05 | Prediction | Nowcast + 4 climate scenario forecasts |

**Climate Scenarios Predicted:**

1. PRESENT (nowcast)
2. RCP45 - 2055
3. RCP45 - 2075  
4. RCP85 - 2055
5. RCP85 - 2075

---

*Generated for JP297Dj Ocean Forecasting: AI, Ecology, and Data Justice*
